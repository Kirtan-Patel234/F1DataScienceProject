{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7q/w_k7x3ss7fsgflp_442s596r0000gn/T/ipykernel_7107/846403147.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[['AirTemp', 'Humidity', 'Rainfall', 'TrackTemp', 'Lap']] = imputer.fit_transform(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.47149927487044324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            Hard New       0.56      0.56      0.56    272176\n",
      "           Hard Used       0.00      0.00      0.00     33557\n",
      "    Intermediate New       0.59      0.41      0.49     57520\n",
      "   Intermediate Used       0.00      0.00      0.00      3454\n",
      "Lluvia Extrema Usado       0.00      0.00      0.00      3881\n",
      "          Medium New       0.44      0.76      0.55    383143\n",
      "         Medium Used       0.49      0.13      0.21    108748\n",
      "            Soft New       0.44      0.05      0.09     96781\n",
      "           Soft Used       0.42      0.29      0.34    159058\n",
      "             Wet New       0.46      0.22      0.30     14583\n",
      "\n",
      "            accuracy                           0.47   1132901\n",
      "           macro avg       0.34      0.24      0.25   1132901\n",
      "        weighted avg       0.46      0.47      0.43   1132901\n",
      "\n",
      "--------------------------------------------------\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.45868262098806517\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            Hard New       0.51      0.66      0.57    272176\n",
      "           Hard Used       0.17      0.02      0.03     33557\n",
      "    Intermediate New       0.48      0.43      0.45     57520\n",
      "   Intermediate Used       0.10      0.01      0.02      3454\n",
      "Lluvia Extrema Usado       0.24      0.15      0.19      3881\n",
      "          Medium New       0.45      0.63      0.52    383143\n",
      "         Medium Used       0.41      0.14      0.21    108748\n",
      "            Soft New       0.29      0.09      0.14     96781\n",
      "           Soft Used       0.41      0.28      0.33    159058\n",
      "             Wet New       0.50      0.26      0.34     14583\n",
      "\n",
      "            accuracy                           0.46   1132901\n",
      "           macro avg       0.36      0.27      0.28   1132901\n",
      "        weighted avg       0.43      0.46      0.42   1132901\n",
      "\n",
      "--------------------------------------------------\n",
      "Model: Random Forest\n",
      "Accuracy: 0.4578228812579387\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            Hard New       0.52      0.63      0.57    272176\n",
      "           Hard Used       0.17      0.01      0.03     33557\n",
      "    Intermediate New       0.50      0.40      0.45     57520\n",
      "   Intermediate Used       0.12      0.01      0.03      3454\n",
      "Lluvia Extrema Usado       0.28      0.23      0.25      3881\n",
      "          Medium New       0.45      0.64      0.53    383143\n",
      "         Medium Used       0.40      0.15      0.22    108748\n",
      "            Soft New       0.28      0.10      0.15     96781\n",
      "           Soft Used       0.39      0.30      0.34    159058\n",
      "             Wet New       0.46      0.26      0.33     14583\n",
      "\n",
      "            accuracy                           0.46   1132901\n",
      "           macro avg       0.36      0.27      0.29   1132901\n",
      "        weighted avg       0.43      0.46      0.43   1132901\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('../Weather/merged_weather_tyre_data_2019.csv')\n",
    "\n",
    "# Define features and target\n",
    "X = data[['AirTemp', 'Humidity', 'Rainfall', 'TrackTemp', 'GP', 'Lap']]\n",
    "y = data['Tyres']\n",
    " \n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X[['AirTemp', 'Humidity', 'Rainfall', 'TrackTemp', 'Lap']] = imputer.fit_transform(\n",
    "    X[['AirTemp', 'Humidity', 'Rainfall', 'TrackTemp', 'Lap']]\n",
    ")\n",
    "\n",
    "# Drop rows where 'Tyres' is missing\n",
    "X = X.dropna()\n",
    "y = y[X.index]\n",
    "\n",
    "# One-hot encode the categorical column 'GP'\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "X_encoded = pd.DataFrame(\n",
    "    encoder.fit_transform(X[['GP']]),\n",
    "    columns=encoder.get_feature_names_out(['GP']),\n",
    "    index=X.index  # Ensure index alignment\n",
    ")\n",
    "# Add one-hot encoded columns to X and drop the original 'GP' column\n",
    "X = pd.concat([X.drop(columns=['GP']), X_encoded], axis=1)\n",
    "\n",
    "# Reset indices to ensure alignment between X and y\n",
    "X = X.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(kernel='rbf')  # Using RBF kernel for SVM\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Cross-validation for robustness\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    print(f\"Cross-validation scores for {name}: {scores}\")\n",
    "    print(f\"Mean CV Accuracy: {scores.mean()}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
